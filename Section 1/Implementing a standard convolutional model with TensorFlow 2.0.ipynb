{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing a standard convolutional model with TensorFlow 2.0",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL5AiRXgc4i6",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacktPublishing/Generative-Adversarial-Networks-GANs-with-TensorFlow-2.0/blob/master/Section%201/Implementing%20a%20standard%20convolutional%20model%20with%20TensorFlow%202.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogqtj2Po02rF",
        "colab_type": "text"
      },
      "source": [
        "# Implementing a standard convolutional model with TensorFlow 2.0\n",
        "\n",
        "Along this notebook we'll explain how to use the power of cloud computing using Google Colab and the brand new TensorFlow 2.0 to train a deep learning model for a classical example: the handwritten digits classification problem using the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "For this classification problem we will use an architecture based on the **LeNet-5** ([*LeCunn et. al, 1998*](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)), a known Convolutional Neural Network (CNN) architecture which will be described below.\n",
        "\n",
        "\n",
        "### Problem statement:\n",
        "\n",
        "Before we tackle the problem with CNNs, let's understand what we'll be doing: If we write a digit, we want to be able to determine what digit we have written.\n",
        "\n",
        "> #### What do we need to do?\n",
        "> Use TensorFlow 2.0  to train a Deep Learning model using a known dataset: [MNIST](https://en.wikipedia.org/wiki/MNIST_database).\n",
        ">\n",
        "> Specifically, we are going to do the following:\n",
        "> - Update and import TensorFlow 2.0\n",
        "> - Load the dataset and normalize data\n",
        "> - Build the model and set hyperparameters \n",
        "> - Fit the model and predict data\n",
        ">\n",
        "> Keep in mind that we want to understand how our development environmet will work and how we will use it along with TensorFlow 2.0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXOewXizCk_K",
        "colab_type": "text"
      },
      "source": [
        "## Upgrading to TensorFlow 2.0\n",
        "\n",
        "First of all, we need to be sure that we're using the version 2.0 of TensorFlow. To install it we will use `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0sMDBqOCvdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow==2.0.0 tensorboard==2.0.0\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYvUnRiPCaOc",
        "colab_type": "text"
      },
      "source": [
        "## The MNIST database\n",
        "\n",
        "Now, let's explore a bit about the dataset that we will use for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLcBUFz20Ukw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML\n",
        "url = 'https://en.wikipedia.org/wiki/MNIST_database'\n",
        "iframe = '<iframe src=' + url + ' width=\"100%\" height=350></iframe>'\n",
        "HTML(iframe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EacGCZS1bOB",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "We just need to import the dataset and split it into training and testing subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S1WH_XG1lOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import numpy\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# We will fix a random seed for reproducibility\n",
        "seed = 11\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOuW0vLyRmzV",
        "colab_type": "text"
      },
      "source": [
        "Once we load the dataset, we can sneak peek one of its elements to see how they look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qoy-nzt1vSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We load the MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_imgs, train_lbls), (test_imgs, test_lbls) = mnist.load_data()\n",
        "\n",
        "# Display first element from (train_imgs, train_lbls)\n",
        "plt.title(\"First element from training dataset:\")\n",
        "plt.imshow(train_imgs[0], cmap=\"gray\")\n",
        "plt.grid(False)\n",
        "print(f\"First label from training dataset: {train_lbls[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfoAXdHa15cE",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess dataset\n",
        "\n",
        "We just need to reshape the input tensor to feed the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF1DdZYS1xQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We preprocess the input data to feed the neural network\n",
        "trn, trw, trh = train_imgs.shape\n",
        "tsn, tsw, tsh = test_imgs.shape\n",
        "train_imgs = train_imgs.reshape((trn, trw, trh, 1)).astype('float32')\n",
        "test_imgs = test_imgs.reshape((tsn, tsw, tsh, 1)).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khGpNOF33EWE",
        "colab_type": "text"
      },
      "source": [
        "### Let's create the model with the TF Keras module!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMlFkkLO3ICH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We create a Keras sequential model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                        input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D(2, 2),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(2, 2),\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu_QPQ3B3bUv",
        "colab_type": "text"
      },
      "source": [
        "We can check out a summary of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7kTOaeC3WHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZyiHwZ63uPu",
        "colab_type": "text"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "First we need to compile the model and set the number of training epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j23-WDp3paQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We compile our model\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdZVj0ZDSe0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We train the model\n",
        "epochs = 3\n",
        "model.fit(train_imgs, train_lbls, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf04lGv35vJO",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIAhEC4J5Rt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We test the model with testing data\n",
        "test_loss, test_acc = model.evaluate(test_imgs, test_lbls, verbose=False)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbKkUDF8QES",
        "colab_type": "text"
      },
      "source": [
        "## Predict with trained model\n",
        "\n",
        "Now that we have a model, how do we use it?\n",
        "\n",
        "It is as simple as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7kWHeIv8NLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remembering that the first image from the training set is a 5:\n",
        "print(f\"The label of testing image: {test_lbls[0]}\")\n",
        "plt.title(\"Testing image:\")\n",
        "plt.imshow(numpy.squeeze(test_imgs[[0]]), cmap=\"gray\")\n",
        "plt.grid(False)\n",
        "print()\n",
        "\n",
        "# Let's now print a prediction:\n",
        "prediction_vector = model.predict(test_imgs[[0]])\n",
        "predicted_digit = numpy.argmax(prediction_vector)\n",
        "print(f\"The 0-9 prediction is: {predicted_digit}\")\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}